%-------------------DAS-------------------------
Having advanced an ensemble of $N$ model states to the time at which an observation is available, 
the filter unites two basic quantities: the observation $y$, and $N$ prior estimates of the observation, $y^{\text{pri}}_{n}$, predicted by the ensemble. 
Bayes' theorem states that the conditional probability distribution of the observation, given the prior ensemble estimate on the one hand, and the physical measurement on the other, is the product of their respective probability distributions.
The resulting joint posterior probability distribution has variance 
\begin{eqnarray}
	\sigma_y^{\text{po}} = 
\left[
	\frac{1}{\sigma_y^{\text{pri}}}
	+
	\frac{1}{R}
\right]^{-1},
\label{eq:sigma_a}
\end{eqnarray}
where $\sigma_y^{\text{pri}}$ is  the prior variance of the observation implied by the ensemble, and $R$ is the variance of the observation itself (i.e. the measurement error).
The ensemble mean of this joint probability distribution is given by
\begin{eqnarray}
	\left< y^{\text{po}}_n \right> = \sigma_y^{\text{po}} 
	\left[
		\frac{\left< y^{\text{pri}}_n \right>}{\sigma_y^{\text{pri}}} +
		\frac{y}{R} 
	\right].
\label{eq:y_a}
\end{eqnarray}

Given an update $\Delta y =  y^{\text{po}} - y^{\text{pri}}$ in the observation space, ensemble filters compute a corresponding update in the model state (in this study: the wind, surface pressure, and temperature fields of an atmospheric model) via linear regression \citep{Anderson2003}:
\begin{eqnarray}
 \Delta x_{i} = 
\left(
	\frac{c_{x_iy}}{\sigma_y}
\right)
\Delta y,
\label{eq:state_update}
\end{eqnarray}
where $x_i$ represents a component of the model state and $c_{x_iy}$ represents the prior covariance between the state component $x_i$ and the observation $y$.

Ensemble assimilation algorithms are novel because they estimate the covariance and variance terms in the above equations using an ensemble of model simulations, rather than prescribing them, i.e. 
\begin{eqnarray}
c_{x_iy} &=& 
\left<
e_{{x_i},n} 
e_{{y},n}
\right>,
\label{eq:covariance} 
\end{eqnarray}
%
%\sigma_b^2 &=& 
%\left<
%\left( y_{b,n} - \left< y_b \right>   \right)^2
%\right>  
%\label{eq:sigma_b} \\
%
%\sigma_a^2 &=& 
%\left<
%\left( y_{a,n} - \left< y_a \right>   \right)^2
%\right>,  
%\label{eq:sigma_a} 
%
where 
\begin{eqnarray}
	e_{{x_i},n} &=& x_{i,n} - \left< x_{i,n} \right>   \label{eq:exn} \\
	e_{y,n} &=& y_{n} - \left< y_{n} \right>    \label{eq:eyn}
\end{eqnarray}
are the deviations of each ensemble member from the ensemble mean.

Thus the error statistics can vary in time and space (according to the physical relationships simulated in the model), and are updated with new information whenever a new observation comes in.  
In a successful ensemble assimilation system, these terms should reflect the true error statistics of the model system.
If not, the ensemble filter will diverge, i.e. the uncertainty predicted by the ensemble will increasingly underestimate the true error, eventually leading to the rejection of new observations.

The experiments in this study use the Ensemble Adjustment Kalman Filter (EAKF) of \citet{anderson2001}, which computes the linear regression (\ref{eq:state_update}) for the ensemble mean, and then computes the state-space ensemble deviations that correspond to the updated ensemble variance (\ref{eq:sigma_a}), which is also linearly regressed from the observation space to the state space (see \citet{Anderson2003}). 
